{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import midi\n",
    "\n",
    "\n",
    "\n",
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from miditoolkit.midi import parser as mid_parser\n",
    "from miditoolkit.pianoroll import parser as pr_parser\n",
    "from miditoolkit.pianoroll import utils\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import music21\n",
    "# score = music21.converter.parse('beethoven_hammerklavier_1.mid')\n",
    "# key = score.analyze('key')\n",
    "# print(key.tonic.name, key.mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of inputs  1018\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_samples = [] # array of array frequencies\n",
    "train_labels = []  # [ [1, 0, 0,0... ], [ 0,0,0,1,0,0,0....] , ...  ]\n",
    "keys = [\"CfMaj\", \"GfMaj\", \"DfMaj\", \"AfMaj\", \"EfMaj\", \"BfMaj\", \"FMaj\", \"CMaj\", \"GMaj\", \"DMaj\", \"AMaj\", \"EMaj\", \"BMaj\", \"FsMaj\",  \"CsMaj\",\n",
    "\"AfMin\", \"EfMin\", \"BfMin\", \"FMin\", \"CMin\", \"GMin\", \"DMin\", \"AMin\", \"EMin\", \"BMin\", \"FsMin\", \"CsMin\", \"GsMin\", \"DsMin\", \"AsMin\"]\n",
    "\n",
    "\n",
    "totalNotes = 0\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith(\".mid\"): \n",
    "        # print(\"hello\")\n",
    "        mido_obj = mid_parser.MidiFile(filename)\n",
    "        for j in range(len(mido_obj.instruments)):\n",
    "            notes = mido_obj.instruments[j].notes\n",
    "            totalNotes += 1\n",
    "            random.shuffle(notes)\n",
    "            # print(\"length of notes: \", len(notes))\n",
    "            LABEL = []\n",
    "            for i in range(len(keys)):\n",
    "                try:\n",
    "                    filename.index(keys[i])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                else:\n",
    "                    temp = [0]*30\n",
    "                    temp[i] = 1\n",
    "                    \n",
    "                    # print(temp)\n",
    "                    # train_labels = np.append(train_labels, temp, axis = 0)\n",
    "\n",
    "                    LABEL = temp\n",
    "                    break\n",
    "\n",
    "            frequency = [0]*12 \n",
    "            \n",
    "            for i in range(len(notes)):\n",
    "                if i % 100 == 0 and i != 0:\n",
    "                    \n",
    "                    total = sum(frequency)\n",
    "                    \n",
    "                    for x in range(len(frequency)):\n",
    "                        frequency[x] = frequency[x] / total\n",
    "\n",
    "                    train_samples.append(frequency)\n",
    "                    train_labels.append(LABEL)\n",
    "\n",
    "                    frequency = [0] * 12\n",
    "                frequency[notes[i].pitch % 12] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)\n",
    "\n",
    "# print(train_samples[100])           \n",
    "# print(train_labels[100])\n",
    "print(\"# of inputs \", len(train_samples))\n",
    "\n",
    "pitchToNotes = [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23 ] # goes from C to B, 12 semitones, any factors of number = note\n",
    "# C, C#, D, D#, E, F, F#, G, G#, A, A#, B\n",
    "print(totalNotes)\n",
    "# print(train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 24)                312       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 48)                1200      \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 30)                1470      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,982\n",
      "Trainable params: 2,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 24, input_shape = (12,), activation = 'relu'),\n",
    "    \n",
    "    Dense(units = 48, activation = 'relu'),\n",
    "    \n",
    "    \n",
    "    Dense(units = 30, activation = \"softmax\"),\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup internal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate = 0.005), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train + Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "26/26 - 1s - loss: 2.9552 - accuracy: 0.1916 - val_loss: 2.4604 - val_accuracy: 0.3529 - 504ms/epoch - 19ms/step\n",
      "Epoch 2/60\n",
      "26/26 - 0s - loss: 2.2286 - accuracy: 0.3010 - val_loss: 1.9198 - val_accuracy: 0.3431 - 52ms/epoch - 2ms/step\n",
      "Epoch 3/60\n",
      "26/26 - 0s - loss: 1.6363 - accuracy: 0.4521 - val_loss: 1.3997 - val_accuracy: 0.6324 - 54ms/epoch - 2ms/step\n",
      "Epoch 4/60\n",
      "26/26 - 0s - loss: 1.2181 - accuracy: 0.5971 - val_loss: 1.0786 - val_accuracy: 0.6029 - 50ms/epoch - 2ms/step\n",
      "Epoch 5/60\n",
      "26/26 - 0s - loss: 0.9848 - accuracy: 0.6560 - val_loss: 0.9065 - val_accuracy: 0.7010 - 52ms/epoch - 2ms/step\n",
      "Epoch 6/60\n",
      "26/26 - 0s - loss: 0.8293 - accuracy: 0.7420 - val_loss: 0.7905 - val_accuracy: 0.7010 - 54ms/epoch - 2ms/step\n",
      "Epoch 7/60\n",
      "26/26 - 0s - loss: 0.6827 - accuracy: 0.7924 - val_loss: 0.6473 - val_accuracy: 0.7990 - 53ms/epoch - 2ms/step\n",
      "Epoch 8/60\n",
      "26/26 - 0s - loss: 0.5849 - accuracy: 0.8366 - val_loss: 0.5282 - val_accuracy: 0.8873 - 54ms/epoch - 2ms/step\n",
      "Epoch 9/60\n",
      "26/26 - 0s - loss: 0.4993 - accuracy: 0.8526 - val_loss: 0.4464 - val_accuracy: 0.9020 - 53ms/epoch - 2ms/step\n",
      "Epoch 10/60\n",
      "26/26 - 0s - loss: 0.4372 - accuracy: 0.8894 - val_loss: 0.3805 - val_accuracy: 0.9314 - 53ms/epoch - 2ms/step\n",
      "Epoch 11/60\n",
      "26/26 - 0s - loss: 0.3812 - accuracy: 0.8968 - val_loss: 0.3898 - val_accuracy: 0.9118 - 51ms/epoch - 2ms/step\n",
      "Epoch 12/60\n",
      "26/26 - 0s - loss: 0.3388 - accuracy: 0.9189 - val_loss: 0.3166 - val_accuracy: 0.9314 - 50ms/epoch - 2ms/step\n",
      "Epoch 13/60\n",
      "26/26 - 0s - loss: 0.3180 - accuracy: 0.9165 - val_loss: 0.2917 - val_accuracy: 0.9314 - 56ms/epoch - 2ms/step\n",
      "Epoch 14/60\n",
      "26/26 - 0s - loss: 0.2836 - accuracy: 0.9263 - val_loss: 0.3030 - val_accuracy: 0.9216 - 52ms/epoch - 2ms/step\n",
      "Epoch 15/60\n",
      "26/26 - 0s - loss: 0.3139 - accuracy: 0.9029 - val_loss: 0.3184 - val_accuracy: 0.9020 - 56ms/epoch - 2ms/step\n",
      "Epoch 16/60\n",
      "26/26 - 0s - loss: 0.2693 - accuracy: 0.9189 - val_loss: 0.2538 - val_accuracy: 0.9461 - 54ms/epoch - 2ms/step\n",
      "Epoch 17/60\n",
      "26/26 - 0s - loss: 0.2346 - accuracy: 0.9275 - val_loss: 0.2558 - val_accuracy: 0.9412 - 49ms/epoch - 2ms/step\n",
      "Epoch 18/60\n",
      "26/26 - 0s - loss: 0.2273 - accuracy: 0.9324 - val_loss: 0.2491 - val_accuracy: 0.9461 - 50ms/epoch - 2ms/step\n",
      "Epoch 19/60\n",
      "26/26 - 0s - loss: 0.2135 - accuracy: 0.9373 - val_loss: 0.2610 - val_accuracy: 0.9216 - 47ms/epoch - 2ms/step\n",
      "Epoch 20/60\n",
      "26/26 - 0s - loss: 0.2209 - accuracy: 0.9324 - val_loss: 0.2446 - val_accuracy: 0.9314 - 45ms/epoch - 2ms/step\n",
      "Epoch 21/60\n",
      "26/26 - 0s - loss: 0.2088 - accuracy: 0.9447 - val_loss: 0.2150 - val_accuracy: 0.9510 - 49ms/epoch - 2ms/step\n",
      "Epoch 22/60\n",
      "26/26 - 0s - loss: 0.2074 - accuracy: 0.9373 - val_loss: 0.2297 - val_accuracy: 0.9265 - 51ms/epoch - 2ms/step\n",
      "Epoch 23/60\n",
      "26/26 - 0s - loss: 0.2035 - accuracy: 0.9447 - val_loss: 0.2300 - val_accuracy: 0.9461 - 53ms/epoch - 2ms/step\n",
      "Epoch 24/60\n",
      "26/26 - 0s - loss: 0.1984 - accuracy: 0.9361 - val_loss: 0.2190 - val_accuracy: 0.9412 - 57ms/epoch - 2ms/step\n",
      "Epoch 25/60\n",
      "26/26 - 0s - loss: 0.1869 - accuracy: 0.9447 - val_loss: 0.2197 - val_accuracy: 0.9314 - 52ms/epoch - 2ms/step\n",
      "Epoch 26/60\n",
      "26/26 - 0s - loss: 0.1710 - accuracy: 0.9558 - val_loss: 0.2197 - val_accuracy: 0.9412 - 74ms/epoch - 3ms/step\n",
      "Epoch 27/60\n",
      "26/26 - 0s - loss: 0.1702 - accuracy: 0.9447 - val_loss: 0.2543 - val_accuracy: 0.9265 - 96ms/epoch - 4ms/step\n",
      "Epoch 28/60\n",
      "26/26 - 0s - loss: 0.1671 - accuracy: 0.9521 - val_loss: 0.2134 - val_accuracy: 0.9363 - 99ms/epoch - 4ms/step\n",
      "Epoch 29/60\n",
      "26/26 - 0s - loss: 0.1823 - accuracy: 0.9349 - val_loss: 0.2155 - val_accuracy: 0.9412 - 82ms/epoch - 3ms/step\n",
      "Epoch 30/60\n",
      "26/26 - 0s - loss: 0.1804 - accuracy: 0.9349 - val_loss: 0.2389 - val_accuracy: 0.9216 - 89ms/epoch - 3ms/step\n",
      "Epoch 31/60\n",
      "26/26 - 0s - loss: 0.1586 - accuracy: 0.9447 - val_loss: 0.1968 - val_accuracy: 0.9461 - 96ms/epoch - 4ms/step\n",
      "Epoch 32/60\n",
      "26/26 - 0s - loss: 0.1616 - accuracy: 0.9472 - val_loss: 0.2014 - val_accuracy: 0.9510 - 83ms/epoch - 3ms/step\n",
      "Epoch 33/60\n",
      "26/26 - 0s - loss: 0.1412 - accuracy: 0.9558 - val_loss: 0.2252 - val_accuracy: 0.9461 - 65ms/epoch - 2ms/step\n",
      "Epoch 34/60\n",
      "26/26 - 0s - loss: 0.1724 - accuracy: 0.9447 - val_loss: 0.2561 - val_accuracy: 0.9314 - 69ms/epoch - 3ms/step\n",
      "Epoch 35/60\n",
      "26/26 - 0s - loss: 0.1691 - accuracy: 0.9410 - val_loss: 0.2055 - val_accuracy: 0.9461 - 62ms/epoch - 2ms/step\n",
      "Epoch 36/60\n",
      "26/26 - 0s - loss: 0.1585 - accuracy: 0.9521 - val_loss: 0.2029 - val_accuracy: 0.9412 - 59ms/epoch - 2ms/step\n",
      "Epoch 37/60\n",
      "26/26 - 0s - loss: 0.1582 - accuracy: 0.9423 - val_loss: 0.2329 - val_accuracy: 0.9412 - 62ms/epoch - 2ms/step\n",
      "Epoch 38/60\n",
      "26/26 - 0s - loss: 0.1409 - accuracy: 0.9607 - val_loss: 0.2178 - val_accuracy: 0.9412 - 91ms/epoch - 3ms/step\n",
      "Epoch 39/60\n",
      "26/26 - 0s - loss: 0.1310 - accuracy: 0.9558 - val_loss: 0.2053 - val_accuracy: 0.9363 - 57ms/epoch - 2ms/step\n",
      "Epoch 40/60\n",
      "26/26 - 0s - loss: 0.1442 - accuracy: 0.9545 - val_loss: 0.2067 - val_accuracy: 0.9363 - 57ms/epoch - 2ms/step\n",
      "Epoch 41/60\n",
      "26/26 - 0s - loss: 0.1655 - accuracy: 0.9435 - val_loss: 0.2368 - val_accuracy: 0.9412 - 60ms/epoch - 2ms/step\n",
      "Epoch 42/60\n",
      "26/26 - 0s - loss: 0.1463 - accuracy: 0.9496 - val_loss: 0.2082 - val_accuracy: 0.9461 - 56ms/epoch - 2ms/step\n",
      "Epoch 43/60\n",
      "26/26 - 0s - loss: 0.1328 - accuracy: 0.9619 - val_loss: 0.2274 - val_accuracy: 0.9216 - 59ms/epoch - 2ms/step\n",
      "Epoch 44/60\n",
      "26/26 - 0s - loss: 0.1414 - accuracy: 0.9459 - val_loss: 0.2206 - val_accuracy: 0.9314 - 55ms/epoch - 2ms/step\n",
      "Epoch 45/60\n",
      "26/26 - 0s - loss: 0.1295 - accuracy: 0.9570 - val_loss: 0.1947 - val_accuracy: 0.9510 - 61ms/epoch - 2ms/step\n",
      "Epoch 46/60\n",
      "26/26 - 0s - loss: 0.1382 - accuracy: 0.9521 - val_loss: 0.2131 - val_accuracy: 0.9510 - 58ms/epoch - 2ms/step\n",
      "Epoch 47/60\n",
      "26/26 - 0s - loss: 0.1267 - accuracy: 0.9558 - val_loss: 0.2169 - val_accuracy: 0.9314 - 57ms/epoch - 2ms/step\n",
      "Epoch 48/60\n",
      "26/26 - 0s - loss: 0.1307 - accuracy: 0.9582 - val_loss: 0.2076 - val_accuracy: 0.9412 - 58ms/epoch - 2ms/step\n",
      "Epoch 49/60\n",
      "26/26 - 0s - loss: 0.1214 - accuracy: 0.9582 - val_loss: 0.2337 - val_accuracy: 0.9314 - 55ms/epoch - 2ms/step\n",
      "Epoch 50/60\n",
      "26/26 - 0s - loss: 0.1321 - accuracy: 0.9595 - val_loss: 0.2240 - val_accuracy: 0.9265 - 54ms/epoch - 2ms/step\n",
      "Epoch 51/60\n",
      "26/26 - 0s - loss: 0.1346 - accuracy: 0.9533 - val_loss: 0.3065 - val_accuracy: 0.9069 - 54ms/epoch - 2ms/step\n",
      "Epoch 52/60\n",
      "26/26 - 0s - loss: 0.1302 - accuracy: 0.9668 - val_loss: 0.2255 - val_accuracy: 0.9314 - 57ms/epoch - 2ms/step\n",
      "Epoch 53/60\n",
      "26/26 - 0s - loss: 0.1240 - accuracy: 0.9545 - val_loss: 0.2355 - val_accuracy: 0.9363 - 59ms/epoch - 2ms/step\n",
      "Epoch 54/60\n",
      "26/26 - 0s - loss: 0.1117 - accuracy: 0.9582 - val_loss: 0.2416 - val_accuracy: 0.9412 - 63ms/epoch - 2ms/step\n",
      "Epoch 55/60\n",
      "26/26 - 0s - loss: 0.1354 - accuracy: 0.9472 - val_loss: 0.2428 - val_accuracy: 0.9412 - 55ms/epoch - 2ms/step\n",
      "Epoch 56/60\n",
      "26/26 - 0s - loss: 0.1121 - accuracy: 0.9595 - val_loss: 0.2144 - val_accuracy: 0.9314 - 58ms/epoch - 2ms/step\n",
      "Epoch 57/60\n",
      "26/26 - 0s - loss: 0.1084 - accuracy: 0.9607 - val_loss: 0.2182 - val_accuracy: 0.9363 - 57ms/epoch - 2ms/step\n",
      "Epoch 58/60\n",
      "26/26 - 0s - loss: 0.1232 - accuracy: 0.9595 - val_loss: 0.2572 - val_accuracy: 0.9265 - 63ms/epoch - 2ms/step\n",
      "Epoch 59/60\n",
      "26/26 - 0s - loss: 0.1134 - accuracy: 0.9644 - val_loss: 0.2478 - val_accuracy: 0.9510 - 83ms/epoch - 3ms/step\n",
      "Epoch 60/60\n",
      "26/26 - 0s - loss: 0.1140 - accuracy: 0.9619 - val_loss: 0.2265 - val_accuracy: 0.9363 - 74ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27857956070>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_samples, y = train_labels,  validation_split = 0.2, batch_size = 32, epochs = 60, shuffle = True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8643b8a7eff3350437230864ff517056e946ddccac03083145411b029836a4f0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ComputerModeling')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
